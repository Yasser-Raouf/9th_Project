{"cells":[{"cell_type":"markdown","id":"1ff72243-51c5-43f8-a068-f51b26129f76","metadata":{},"source":["<h2>Table of Contents</h2>\n","<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n","    <ul>\n","    <li><a href=\"https://#Section_1\">Instructions</a></li>\n","    <li><a href=\"https://#Section_2\">About the Data</a></li>\n","    <li><a href=\"https://#Section_3\">Importing Data </a></li>\n","    <li><a href=\"https://#Section_4\">Data Preprocessing</a> </li>\n","    <li><a href=\"https://#Section_5\">One Hot Encoding </a></li>\n","    <li><a href=\"https://#Section_6\">Train and Test Data Split </a></li>\n","    <li><a href=\"https://#Section_7\">Train Logistic Regression, KNN, Decision Tree, SVM, and Linear Regression models and return their appropriate accuracy scores</a></li>\n","</a></li>\n","\n","<hr>\n"]},{"cell_type":"markdown","id":"86eb3d6c-6c7b-4eea-a53b-4f02713b4bec","metadata":{},"source":["# Instructions\n"]},{"cell_type":"markdown","id":"ead7c400-ef26-4315-89dc-9c14d56b4453","metadata":{},"source":["In this notebook, you will  practice all the classification algorithms that we have learned in this course.\n","\n","\n","Below, is where we are going to use the classification algorithms to create a model based on our training data and evaluate our testing data using evaluation metrics learned in the course.\n","\n","We will use some of the algorithms taught in the course, specifically:\n","\n","1. Linear Regression\n","2. KNN\n","3. Decision Trees\n","4. Logistic Regression\n","5. SVM\n","\n","We will evaluate our models using:\n","\n","1.  Accuracy Score\n","2.  Jaccard Index\n","3.  F1-Score\n","4.  LogLoss\n","5.  Mean Absolute Error\n","6.  Mean Squared Error\n","7.  R2-Score\n","\n","Finally, you will use your models to generate the report at the end. \n"]},{"cell_type":"markdown","id":"374126bb-a797-4d19-8763-3d080d584e8c","metadata":{},"source":["# About The Dataset\n"]},{"cell_type":"markdown","id":"c51d9782-82c3-416f-929b-6282f26bf8bf","metadata":{},"source":["The original source of the data is Australian Government's Bureau of Meteorology and the latest data can be gathered from [http://www.bom.gov.au/climate/dwo/](http://www.bom.gov.au/climate/dwo/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01).\n","\n","The dataset to be used has extra columns like 'RainToday' and our target is 'RainTomorrow', which was gathered from the Rattle at [https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData](https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n","\n","\n"]},{"cell_type":"markdown","id":"e75936cd-253a-4c07-8609-20c60ff0becf","metadata":{},"source":["This dataset contains observations of weather metrics for each day from 2008 to 2017. The **weatherAUS.csv** dataset includes the following fields:\n","\n","| Field         | Description                                           | Unit            | Type   |\n","| ------------- | ----------------------------------------------------- | --------------- | ------ |\n","| Date          | Date of the Observation in YYYY-MM-DD                 | Date            | object |\n","| Location      | Location of the Observation                           | Location        | object |\n","| MinTemp       | Minimum temperature                                   | Celsius         | float  |\n","| MaxTemp       | Maximum temperature                                   | Celsius         | float  |\n","| Rainfall      | Amount of rainfall                                    | Millimeters     | float  |\n","| Evaporation   | Amount of evaporation                                 | Millimeters     | float  |\n","| Sunshine      | Amount of bright sunshine                             | hours           | float  |\n","| WindGustDir   | Direction of the strongest gust                       | Compass Points  | object |\n","| WindGustSpeed | Speed of the strongest gust                           | Kilometers/Hour | object |\n","| WindDir9am    | Wind direction averaged of 10 minutes prior to 9am    | Compass Points  | object |\n","| WindDir3pm    | Wind direction averaged of 10 minutes prior to 3pm    | Compass Points  | object |\n","| WindSpeed9am  | Wind speed averaged of 10 minutes prior to 9am        | Kilometers/Hour | float  |\n","| WindSpeed3pm  | Wind speed averaged of 10 minutes prior to 3pm        | Kilometers/Hour | float  |\n","| Humidity9am   | Humidity at 9am                                       | Percent         | float  |\n","| Humidity3pm   | Humidity at 3pm                                       | Percent         | float  |\n","| Pressure9am   | Atmospheric pressure reduced to mean sea level at 9am | Hectopascal     | float  |\n","| Pressure3pm   | Atmospheric pressure reduced to mean sea level at 3pm | Hectopascal     | float  |\n","| Cloud9am      | Fraction of the sky obscured by cloud at 9am          | Eights          | float  |\n","| Cloud3pm      | Fraction of the sky obscured by cloud at 3pm          | Eights          | float  |\n","| Temp9am       | Temperature at 9am                                    | Celsius         | float  |\n","| Temp3pm       | Temperature at 3pm                                    | Celsius         | float  |\n","| RainToday     | If there was rain today                               | Yes/No          | object |\n","| RainTomorrow  | If there is rain tomorrow                             | Yes/No          | float  |\n","\n","Column definitions were gathered from [http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml](http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n","\n"]},{"cell_type":"markdown","id":"8cd5057f-8ab6-4df2-a3cb-997899f6d114","metadata":{},"source":["## **Import the required libraries**\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Surpress warnings:\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn\n","import warnings\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import sklearn.metrics as metrics\n","import time\n","import gc, sys\n","%matplotlib inline\n","warnings.filterwarnings('ignore')\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import r2_score\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.linear_model import LogisticRegression\n","from sklearn import preprocessing\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn import svm\n","from sklearn.preprocessing import normalize, StandardScaler, MinMaxScaler\n","from sklearn.utils.class_weight import compute_sample_weight\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import jaccard_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import log_loss\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","from __future__ import print_function\n"]},{"cell_type":"markdown","id":"114dea97-d1e6-45f2-9955-aebd36d5dac1","metadata":{},"source":["### Importing the Dataset\n"]},{"cell_type":"code","execution_count":18,"id":"1b5c9381-6722-4e4d-b206-9c6b3574c23c","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Download completed.\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>MinTemp</th>\n","      <th>MaxTemp</th>\n","      <th>Rainfall</th>\n","      <th>Evaporation</th>\n","      <th>Sunshine</th>\n","      <th>WindGustDir</th>\n","      <th>WindGustSpeed</th>\n","      <th>WindDir9am</th>\n","      <th>WindDir3pm</th>\n","      <th>...</th>\n","      <th>Humidity9am</th>\n","      <th>Humidity3pm</th>\n","      <th>Pressure9am</th>\n","      <th>Pressure3pm</th>\n","      <th>Cloud9am</th>\n","      <th>Cloud3pm</th>\n","      <th>Temp9am</th>\n","      <th>Temp3pm</th>\n","      <th>RainToday</th>\n","      <th>RainTomorrow</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2/1/2008</td>\n","      <td>19.5</td>\n","      <td>22.4</td>\n","      <td>15.6</td>\n","      <td>6.2</td>\n","      <td>0.0</td>\n","      <td>W</td>\n","      <td>41</td>\n","      <td>S</td>\n","      <td>SSW</td>\n","      <td>...</td>\n","      <td>92</td>\n","      <td>84</td>\n","      <td>1017.6</td>\n","      <td>1017.4</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>20.7</td>\n","      <td>20.9</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2/2/2008</td>\n","      <td>19.5</td>\n","      <td>25.6</td>\n","      <td>6.0</td>\n","      <td>3.4</td>\n","      <td>2.7</td>\n","      <td>W</td>\n","      <td>41</td>\n","      <td>W</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>83</td>\n","      <td>73</td>\n","      <td>1017.9</td>\n","      <td>1016.4</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>22.4</td>\n","      <td>24.8</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2/3/2008</td>\n","      <td>21.6</td>\n","      <td>24.5</td>\n","      <td>6.6</td>\n","      <td>2.4</td>\n","      <td>0.1</td>\n","      <td>W</td>\n","      <td>41</td>\n","      <td>ESE</td>\n","      <td>ESE</td>\n","      <td>...</td>\n","      <td>88</td>\n","      <td>86</td>\n","      <td>1016.7</td>\n","      <td>1015.6</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>23.5</td>\n","      <td>23.0</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2/4/2008</td>\n","      <td>20.2</td>\n","      <td>22.8</td>\n","      <td>18.8</td>\n","      <td>2.2</td>\n","      <td>0.0</td>\n","      <td>W</td>\n","      <td>41</td>\n","      <td>NNE</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>83</td>\n","      <td>90</td>\n","      <td>1014.2</td>\n","      <td>1011.8</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>21.4</td>\n","      <td>20.9</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2/5/2008</td>\n","      <td>19.7</td>\n","      <td>25.7</td>\n","      <td>77.4</td>\n","      <td>4.8</td>\n","      <td>0.0</td>\n","      <td>W</td>\n","      <td>41</td>\n","      <td>NNE</td>\n","      <td>W</td>\n","      <td>...</td>\n","      <td>88</td>\n","      <td>74</td>\n","      <td>1008.3</td>\n","      <td>1004.8</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>22.5</td>\n","      <td>25.5</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 22 columns</p>\n","</div>"],"text/plain":["       Date  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir  \\\n","0  2/1/2008     19.5     22.4      15.6          6.2       0.0           W   \n","1  2/2/2008     19.5     25.6       6.0          3.4       2.7           W   \n","2  2/3/2008     21.6     24.5       6.6          2.4       0.1           W   \n","3  2/4/2008     20.2     22.8      18.8          2.2       0.0           W   \n","4  2/5/2008     19.7     25.7      77.4          4.8       0.0           W   \n","\n","   WindGustSpeed WindDir9am WindDir3pm  ...  Humidity9am  Humidity3pm  \\\n","0             41          S        SSW  ...           92           84   \n","1             41          W          E  ...           83           73   \n","2             41        ESE        ESE  ...           88           86   \n","3             41        NNE          E  ...           83           90   \n","4             41        NNE          W  ...           88           74   \n","\n","   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n","0       1017.6       1017.4         8         8     20.7     20.9        Yes   \n","1       1017.9       1016.4         7         7     22.4     24.8        Yes   \n","2       1016.7       1015.6         7         8     23.5     23.0        Yes   \n","3       1014.2       1011.8         8         8     21.4     20.9        Yes   \n","4       1008.3       1004.8         8         8     22.5     25.5        Yes   \n","\n","   RainTomorrow  \n","0           Yes  \n","1           Yes  \n","2           Yes  \n","3           Yes  \n","4           Yes  \n","\n","[5 rows x 22 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["path='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillUp/labs/ML-FinalAssignment/Weather_Data.csv'\n","#await download(path, \"Weather_Data.csv\")\n","#filename =\"Weather_Data.csv\"\n","\n","import requests\n","\n","def download(url, filename):\n","    # Make a GET request to the specified URL\n","    response = requests.get(url)\n","    \n","    # Check if the request was successful (status code 200)\n","    if response.status_code == 200:\n","        # Open the file specified by 'filename' in binary write mode\n","        with open(filename, \"wb\") as f:\n","            # Write the content of the response to the file\n","            f.write(response.content)\n","            # Print a message indicating that the download is completed\n","            print(\"Download completed.\")\n","    else:\n","        # Print an error message if the request fails\n","        print(f\"Failed to download from {url}. Status code: {response.status_code}\")\n","\n","download(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillUp/labs/ML-FinalAssignment/Weather_Data.csv\", \"Weather_Data.csv\")\n","\n","df = pd.read_csv(\"Weather_Data.csv\")\n","df.head()"]},{"cell_type":"markdown","id":"49789b4d-0b96-433f-a9b2-e0e92dbdc3a4","metadata":{},"source":["### Data Preprocessing\n"]},{"cell_type":"code","execution_count":23,"id":"e9bb7083-34db-4eaf-878e-d9e62f7fe352","metadata":{},"outputs":[],"source":["# First, we need to perform one hot encoding to convert categorical variables to binary variables.\n","df_sydney_processed = pd.get_dummies(data=df, columns=['RainToday', 'WindGustDir', 'WindDir9am', 'WindDir3pm'])"]},{"cell_type":"markdown","id":"e2d8b302-b050-47ea-bb94-8010a697cdb3","metadata":{},"source":["Next, we replace the values of the 'RainTomorrow' column changing them from a categorical column to a binary column. We do not use the `get_dummies` method because we would end up with two columns for 'RainTomorrow' and we do not want, since 'RainTomorrow' is our target.\n"]},{"cell_type":"code","execution_count":24,"id":"2081b0cd-2c0c-459a-adf8-05ee85b6b8b3","metadata":{},"outputs":[],"source":["df_sydney_processed.replace(['No', 'Yes'], [0,1], inplace=True)"]},{"cell_type":"markdown","id":"7fa9af32-5b06-4d65-8716-a88f629771f3","metadata":{},"source":["### Training Data and Test Data\n"]},{"cell_type":"markdown","id":"4e795750-5a3e-4da5-b4d2-c34dc48de8d8","metadata":{},"source":["Now, we set our 'features' or x values and our Y or target variable.\n"]},{"cell_type":"code","execution_count":25,"id":"e122dd1b-e167-4736-a80d-6288fdceebe1","metadata":{},"outputs":[],"source":["df_sydney_processed.drop('Date',axis=1,inplace=True)\n","\n","df_sydney_processed = df_sydney_processed.astype(float)\n","\n","\n","features = df_sydney_processed.drop(columns='RainTomorrow', axis=1)\n","Y = df_sydney_processed['RainTomorrow']"]},{"cell_type":"markdown","id":"b48559a0-48be-4e78-8268-827e17f9b2ab","metadata":{},"source":["### Linear Regression\n"]},{"cell_type":"code","execution_count":26,"id":"91587f68-541a-4a83-93b4-4937d6b11c5e","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training set - Features: (2616, 66) Training set - Target: (2616,)\n","Testing set - Features: (655, 66) Testing set - Target: (655,)\n","R² for the training data: 0.38691299347235053\n","R² for the test data: 0.4271321073623009\n"]}],"source":["# Split the data into training and testing sets\n","X_train, X_test, Y_train, Y_test = train_test_split(features, Y, test_size=0.2, random_state=10)\n","\n","# Print the shapes of the training and testing sets to verify the split\n","print(\"Training set - Features:\", X_train.shape, \"Training set - Target:\", Y_train.shape)\n","print(\"Testing set - Features:\", X_test.shape, \"Testing set - Target:\", Y_test.shape)\n","\n","# Create and fit the linear regression model\n","model = LinearRegression()\n","model.fit(X_train, Y_train)\n","\n","# Predict on training data\n","Y_train_pred = model.predict(X_train)\n","\n","# Predict on test data\n","Y_test_pred = model.predict(X_test)\n","\n","# Calculate R² for the training data\n","r2_train = r2_score(Y_train, Y_train_pred)\n","print(f\"R² for the training data: {r2_train}\")\n","\n","# Calculate R² for the test data\n","r2_test = r2_score(Y_test, Y_test_pred)\n","print(f\"R² for the test data: {r2_test}\")"]},{"cell_type":"markdown","metadata":{},"source":["Interpretation of R² Values\n","The R² (coefficient of determination) values you have obtained are as follows:\n","\n","R² for the training data: 0.3869\n","R² for the test data: 0.4271\n","Explanation of Results\n","R² Value Interpretation:\n","\n","R² for the training data (0.3869): This value indicates that approximately 38.69% of the variance in the target variable (price) is explained by the features in the training dataset. While this indicates a moderate level of explanatory power, it suggests that a significant portion of the variance is not captured by the model.\n","R² for the test data (0.4271): This value indicates that approximately 42.71% of the variance in the target variable is explained by the features in the test dataset. This is slightly higher than the training R², suggesting that the model performs marginally better on unseen data.\n","Overfitting and Underfitting:\n","\n","Underfitting: Underfitting occurs when a model is too simple and cannot capture the underlying patterns in the data. This typically results in low R² values for both the training and test datasets. In your case, the moderate R² values (around 0.39 and 0.43) suggest that the model might be underfitting slightly, as it is not explaining a large portion of the variance in the data. This indicates that the model may be too simple or that the features selected do not capture all the relevant information.\n","Overfitting: Overfitting occurs when a model is too complex and captures not only the underlying patterns but also the noise in the training data. This often results in a high R² value for the training data and a significantly lower R² value for the test data. In your case, the R² values for both the training and test datasets are relatively close, which suggests that the model is not overfitting. The fact that the test R² is slightly higher than the training R² could be due to variability in the data or the selection of the test set.\n","Possible Actions:\n","Feature Engineering: Consider adding more relevant features or creating polynomial features to capture more complex relationships in the data.\n","Model Complexity: Explore more complex models or regularization techniques to improve the model's ability to capture underlying patterns without overfitting.\n","Data Quality: Ensure that the data is clean, and consider whether additional data could help improve the model's performance.\n","In summary, while the model does not seem to suffer from overfitting, the moderate R² values indicate that there is room for improvement in capturing the variance in the target variable. Exploring additional features, more complex models, or different modeling techniques could help achieve better performance."]},{"cell_type":"code","execution_count":32,"id":"f1bc59ee-f73b-4463-8792-b434e4d6172a","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear Regression Model Evaluation:\n","                      Metric     Value\n","0  Mean Absolute Error (MAE)  0.256318\n","1   Mean Squared Error (MSE)  0.115721\n","2             R-squared (R2)  0.427132\n"]}],"source":["# Split the data into training and testing sets\n","X_train, X_test, Y_train, Y_test = train_test_split(features, Y, test_size=0.2, random_state=10)\n","\n","# Create a linear regression model\n","model = LinearRegression()\n","\n","# Train the model on the training data\n","model.fit(X_train, Y_train)\n","\n","# Make predictions on the testing data\n","Y_pred = model.predict(X_test)\n","\n","# Evaluate the model\n","mse = mean_squared_error(Y_test, Y_pred)\n","mae = mean_absolute_error(Y_test, Y_pred)\n","r2 = r2_score(Y_test, Y_pred)\n","\n","\n","# Use the trained model to make predictions on the testing data\n","predictions = model.predict(X_test)\n","\n","# Show the MAE, MSE, and R2 in a tabular format using data frame for the linear model.\n","\n","# Create a DataFrame to store the evaluation metrics\n","evaluation_df = pd.DataFrame({\n","    'Metric': ['Mean Absolute Error (MAE)', 'Mean Squared Error (MSE)', 'R-squared (R2)'],\n","    'Value': [mae, mse, r2]\n","})\n","\n","# Print the DataFrame\n","print(\"Linear Regression Model Evaluation:\")\n","print(evaluation_df)"]},{"cell_type":"markdown","id":"86cc3e76-f489-4a59-b435-f527c208610d","metadata":{},"source":["### KNN\n"]},{"cell_type":"code","execution_count":29,"id":"64793e85-af1c-486e-8688-f8faf6512627","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Data Evaluation:\n","Mean Absolute Error (MAE): 0.17584097859327216\n","Mean Squared Error (MSE): 0.08887614678899082\n","R-squared (R2): 0.531206283263258\n","Test Data Evaluation:\n","Mean Absolute Error (MAE): 0.2316793893129771\n","Mean Squared Error (MSE): 0.1441793893129771\n","R-squared (R2): 0.28624847110680307\n"]}],"source":["from sklearn.metrics import accuracy_score, jaccard_score, f1_score\n","\n","# Split the data into training and testing sets\n","X_train, X_test, Y_train, Y_test = train_test_split(features, Y, test_size=0.2, random_state=10)\n","\n","# Create a KNN regression model with n_neighbors=4\n","knn_model = KNeighborsRegressor(n_neighbors=4)\n","\n","# Train the KNN model on the training data\n","knn_model.fit(X_train, Y_train)\n","\n","# Make predictions on the training data\n","Y_train_pred = knn_model.predict(X_train)\n","\n","# Calculate evaluation metrics for the training data\n","train_mae = mean_absolute_error(Y_train, Y_train_pred)\n","train_mse = mean_squared_error(Y_train, Y_train_pred)\n","train_r2 = r2_score(Y_train, Y_train_pred)\n","\n","# Print evaluation metrics for the training data\n","print(\"Training Data Evaluation:\")\n","print(\"Mean Absolute Error (MAE):\", train_mae)\n","print(\"Mean Squared Error (MSE):\", train_mse)\n","print(\"R-squared (R2):\", train_r2)\n","\n","# Make predictions on the test data\n","Y_test_pred = knn_model.predict(X_test)\n","\n","# Calculate evaluation metrics for the test data\n","test_mae = mean_absolute_error(Y_test, Y_test_pred)\n","test_mse = mean_squared_error(Y_test, Y_test_pred)\n","test_r2 = r2_score(Y_test, Y_test_pred)\n","\n","# Print evaluation metrics for the test data\n","print(\"Test Data Evaluation:\")\n","print(\"Mean Absolute Error (MAE):\", test_mae)\n","print(\"Mean Squared Error (MSE):\", test_mse)\n","print(\"R-squared (R2):\", test_r2)"]},{"cell_type":"markdown","metadata":{},"source":["In the previous we got an error of\n","\n","\n","\n"," ( 1 # Using the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n","      2 # Use the trained KNN model to make predictions on the testing data\n","----> 3 predictions = KNN.predict(X_test)\n","\n","File c:\\Users\\POP\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\neighbors\\_regression.py:242, in KNeighborsRegressor.predict(self, X)\n","    226 \"\"\"Predict the target for the provided data.\n","    227 \n","    228 Parameters\n","   (...)\n","    237     Target values.\n","    238 \"\"\"\n","    239 if self.weights == \"uniform\":\n","    240     # In that case, we do not need the distances to perform\n","    241     # the weighting so we do not compute them.\n","--> 242     neigh_ind = self.kneighbors(X, return_distance=False)\n","    243     neigh_dist = None\n","    244 else:\n","\n","File c:\\Users\\POP\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:850, in KNeighborsMixin.kneighbors(self, X, n_neighbors, return_distance)\n","    843 use_pairwise_distances_reductions = (\n","    844     self._fit_method == \"brute\"\n","    845     and ArgKmin.is_usable_for(\n","...\n","--> 646 config = get_config().split()\n","    647 if config[0] == b\"OpenBLAS\":\n","    648     return config[1].decode(\"utf-8\")\n","\n","AttributeError: 'NoneType' object has no attribute 'split')\n","\n","\n","the interpretation: \n","This error seems to be related to the configuration of OpenBLAS, a library often used for numerical computations in Python, particularly with libraries like NumPy and scikit-learn. It appears that there might be an issue with retrieving the configuration, leading to a NoneType error when attempting to split it.\n","\n","\n","we solve it by (pip install --upgrade --force-reinstall scikit-learn) # successfully upgraded scikit-learn in your myenv environment\n","\n"]},{"cell_type":"markdown","id":"254250b6-7c79-4edd-bc79-a19d5e1feac7","metadata":{},"source":["### Decision Tree\n"]},{"cell_type":"code","execution_count":30,"id":"334c059a-1bbb-4aec-9a42-ea46d9238300","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Decision Tree Classifier Model Evaluation:\n","Accuracy Score: 0.7648854961832061\n","Jaccard Index: 0.4166666666666667\n","F1 Score: 0.5882352941176471\n"]}],"source":["# Create a decision tree classifier\n","Tree = DecisionTreeClassifier()\n","\n","# Train the decision tree classifier on the training data\n","Tree.fit(X_train, Y_train)\n","\n","# Use the predict method on the testing data and save it to the array `predictions`\n","predictions = Tree.predict(X_test)\n","\n","# Calculate the value for each metric using the appropriate function\n","Tree_Accuracy_Score = accuracy_score(Y_test, predictions)\n","Tree_JaccardIndex = jaccard_score(Y_test, predictions)\n","Tree_F1_Score = f1_score(Y_test, predictions)\n","\n","# Print the evaluation metrics\n","print(\"Decision Tree Classifier Model Evaluation:\")\n","print(\"Accuracy Score:\", Tree_Accuracy_Score)\n","print(\"Jaccard Index:\", Tree_JaccardIndex)\n","print(\"F1 Score:\", Tree_F1_Score)"]},{"cell_type":"markdown","id":"b003ddfe-0e3b-4223-8070-dfe43a43151b","metadata":{},"source":["### Logistic Regression\n"]},{"cell_type":"code","execution_count":15,"id":"bdab2381-8d87-4042-bf49-b631e74d9909","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Logistic Regression Model Evaluation:\n","Accuracy Score: 0.8351145038167939\n","Jaccard Index: 0.5045871559633027\n","F1 Score: 0.6707317073170732\n","Log Loss: 0.3815916633912949\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, jaccard_score, f1_score, log_loss\n","\n","# Split the data into training and testing sets with test_size=0.2 and random_state=1\n","x_train, x_test, y_train, y_test = train_test_split(features, Y, test_size=0.2, random_state=1)\n","\n","# Create and train a LogisticRegression model with solver set to 'liblinear'\n","LR = LogisticRegression(solver='liblinear')\n","LR.fit(x_train, y_train)\n","\n","# Use the trained model to make predictions on the testing data\n","predictions = LR.predict(x_test)\n","predict_proba = LR.predict_proba(x_test)\n","\n","# Calculate the evaluation metrics\n","LR_Accuracy_Score = accuracy_score(y_test, predictions)\n","LR_JaccardIndex = jaccard_score(y_test, predictions)\n","LR_F1_Score = f1_score(y_test, predictions)\n","LR_Log_Loss = log_loss(y_test, predict_proba)\n","\n","# Print the evaluation metrics\n","print(\"Logistic Regression Model Evaluation:\")\n","print(f\"Accuracy Score: {LR_Accuracy_Score}\")\n","print(f\"Jaccard Index: {LR_JaccardIndex}\")\n","print(f\"F1 Score: {LR_F1_Score}\")\n","print(f\"Log Loss: {LR_Log_Loss}\")\n"]},{"cell_type":"markdown","id":"8d58b0b2-b31e-41e5-b52f-262f71f3e259","metadata":{},"source":["### SVM\n"]},{"cell_type":"code","execution_count":33,"id":"4cf0dc36-b215-4061-9cda-f38b9db1739c","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["SVM Model Evaluation:\n","Accuracy Score: 0.7190839694656489\n","Jaccard Index: 0.0\n","F1 Score: 0.0\n"]}],"source":["from sklearn.svm import SVC\n","\n","# Create an SVM model (Support Vector Machine)\n","SVM = SVC() \n","\n","# Train the SVM model on the training data\n","SVM.fit(X_train, Y_train)\n","\n","# Make predictions on the testing data\n","predictions = SVM.predict(X_test)\n","\n","# Evaluate the SVM model\n","SVM_Accuracy_Score = accuracy_score(Y_test, predictions)\n","SVM_JaccardIndex = jaccard_score(Y_test, predictions)\n","SVM_F1_Score = f1_score(Y_test, predictions)\n","\n","# Print evaluation metrics for SVM\n","print(\"SVM Model Evaluation:\")\n","print(\"Accuracy Score:\", SVM_Accuracy_Score)\n","print(\"Jaccard Index:\", SVM_JaccardIndex)\n","print(\"F1 Score:\", SVM_F1_Score)"]},{"cell_type":"markdown","id":"506f03ee-5914-40fa-b6c3-787afc728957","metadata":{},"source":["### Report\n"]},{"cell_type":"code","execution_count":39,"id":"b6b2cee7-4b35-4677-b3ae-c75b1cd29413","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Report\n","\n","Model Comparison:\n","                      Model       MSE       MAE  R2 Score  Accuracy  \\\n","0         Linear Regression  0.115721  0.256318  0.427132       NaN   \n","1            KNN Regression  0.144179  0.231679  0.286248       NaN   \n","2       Logistic Regression       NaN       NaN       NaN  0.835115   \n","3  Decision Tree Classifier       NaN       NaN       NaN  0.764885   \n","4    Support Vector Machine       NaN       NaN       NaN  0.719084   \n","\n","   Jaccard Index  F1 Score  Log Loss  \n","0            NaN       NaN       NaN  \n","1            NaN       NaN       NaN  \n","2       0.504587  0.670732  0.381592  \n","3       0.416667  0.588235       NaN  \n","4       0.000000  0.000000       NaN  \n"]}],"source":["print(\"Report\")\n","\n","# Create a DataFrame to compare the evaluation metrics\n","comparison_df = pd.DataFrame({\n","    'Model': ['Linear Regression', 'KNN Regression', 'Logistic Regression', 'Decision Tree Classifier', 'Support Vector Machine'],\n","    'MSE': [mse, test_mse, None, None, None],\n","    'MAE': [mae, test_mae, None, None, None],\n","    'R2 Score': [r2, test_r2, None, None, None],\n","    'Accuracy': [None, None, LR_Accuracy_Score, Tree_Accuracy_Score, SVM_Accuracy_Score],\n","    'Jaccard Index': [None, None, LR_JaccardIndex, Tree_JaccardIndex, SVM_JaccardIndex],\n","    'F1 Score': [None, None, LR_F1_Score, Tree_F1_Score, SVM_F1_Score],\n","    'Log Loss': [None, None, LR_Log_Loss, None, None],\n","})\n","\n","# Print the comparison DataFrame\n","print(\"\\nModel Comparison:\")\n","print(comparison_df)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Conclusion: the highest accuracy related to the Logistic Regression model.\n","### so if are going to predect the Rainfall in spacific area you should use the Logistic Regression model."]},{"cell_type":"markdown","metadata":{},"source":["### Linear Regression\n","Mean Squared Error (MSE): 0.115721\n","Mean Absolute Error (MAE): 0.256318\n","R² Score: 0.427132\n","Interpretation:\n","\n","The Linear Regression model has a moderate R² score, indicating that approximately 42.7% of the variability in the target variable is explained by the model.\n","The errors (MSE and MAE) are relatively low, suggesting the model's predictions are reasonably close to the actual values.\n","\n","### KNN Regression\n","Mean Squared Error (MSE): 0.144179\n","Mean Absolute Error (MAE): 0.231679\n","R² Score: 0.286248\n","Interpretation:\n","\n","The KNN Regression model has a lower R² score (28.6%), indicating it explains less variance in the target variable compared to Linear Regression.\n","The errors are slightly higher than those of Linear Regression, suggesting it might not perform as well on this dataset.\n","\n","### Logistic Regression\n","Accuracy: 0.835115\n","Jaccard Index: 0.504587\n","F1 Score: 0.670732\n","Log Loss: 0.381592\n","Interpretation:\n","\n","The Logistic Regression model has a high accuracy (83.5%), indicating it correctly classifies the majority of the test instances.\n","The Jaccard Index (0.504587) and F1 Score (0.670732) show that the model performs well in terms of precision and recall balance.\n","The Log Loss is relatively low, suggesting good performance in terms of probability predictions.\n","\n","### Decision Tree Classifier\n","Accuracy: 0.764885\n","Jaccard Index: 0.416667\n","F1 Score: 0.588235\n","Interpretation:\n","\n","The Decision Tree Classifier has a decent accuracy (76.5%) but lower than Logistic Regression.\n","The Jaccard Index and F1 Score are also lower compared to Logistic Regression, indicating it may not be as effective in balancing precision and recall.\n","\n","### Support Vector Machine (SVM)\n","Accuracy: 0.719084\n","Jaccard Index: 0.000000\n","F1 Score: 0.000000\n","Interpretation:\n","\n","The SVM model has an accuracy of 71.9%, which is lower than both Logistic Regression and Decision Tree Classifier.\n","The Jaccard Index and F1 Score being zero indicate that the SVM model failed to identify any positives, likely predicting all instances as the negative class.\n","\n","### Overall Comparison\n","Best Model for Regression: Based on R² Score, Linear Regression performs better than KNN Regression, explaining more variance in the target variable.\n","Best Model for Classification: Logistic Regression outperforms both Decision Tree Classifier and SVM in terms of accuracy, Jaccard Index, F1 Score, and Log Loss.\n","\n","### Recommendations\n","Regression Tasks: Use Linear Regression, as it provides better error metrics and explains more variability in the target.\n","Classification Tasks: Use Logistic Regression, as it has the highest accuracy and balanced performance metrics.\n","Note: The SVM model’s poor performance could be due to suboptimal parameter choices or the nature of the dataset, suggesting a need for further tuning or a different kernel function."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
